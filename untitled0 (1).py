# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SLWh5OOmMZcJ5qm4lPCeoqwqeFtF0WER
"""

import numpy as np
import pandas as pd
import tensorflow as tf
from sklearn.metrics import precision_score, recall_score, f1_score
from sklearn.preprocessing import MinMaxScaler
import matplotlib.pyplot as plt
import random

# -------------------------------
# 1Ô∏è‚É£ Synthetic Multivariate Time-Series Generation
# -------------------------------

def generate_synthetic_timeseries(n_steps=5000, n_features=5):
    time = np.arange(n_steps)
    data = []

    for f in range(n_features):
        seasonal = np.sin(0.02 * time + f)
        trend = time * 0.0005 * (f + 1)
        noise = np.random.normal(0, 0.05, n_steps)
        feature = seasonal + trend + noise
        data.append(feature)

    data = np.vstack(data).T

    labels = np.zeros(n_steps)

    # Inject point anomalies
    for _ in range(30):
        idx = random.randint(10, n_steps - 10)
        data[idx] += np.random.normal(2, 0.5, n_features)
        labels[idx] = 1

    # Inject collective anomalies
    for _ in range(10):
        start = random.randint(0, n_steps - 50)
        length = random.randint(10, 50)
        data[start:start+length] += np.random.normal(1, 0.3, (length, n_features))
        labels[start:start+length] = 1

    # Inject contextual anomalies (shift only 1 feature)
    for _ in range(10):
        idx = random.randint(10, n_steps - 10)
        data[idx, 0] += 3
        labels[idx] = 1

    return data, labels


# -------------------------------
# 2Ô∏è‚É£ Prepare Data (Scaling + Windowing)
# -------------------------------

def create_sequences(X, seq_length=50):
    Xs = []
    for i in range(len(X) - seq_length):
        Xs.append(X[i:(i + seq_length)])
    return np.array(Xs)


data, labels = generate_synthetic_timeseries()

scaler = MinMaxScaler()
data_scaled = scaler.fit_transform(data)

SEQ_LENGTH = 50
X_sequences = create_sequences(data_scaled, SEQ_LENGTH)
y_sequences = labels[SEQ_LENGTH:]

normal_idx = np.where(y_sequences == 0)[0]
abnormal_idx = np.where(y_sequences == 1)[0]

X_train = X_sequences[normal_idx]

print("Training samples:", X_train.shape)


# -------------------------------
# 3Ô∏è‚É£ Build LSTM Autoencoder Model
# -------------------------------

model = tf.keras.Sequential([
    tf.keras.layers.LSTM(64, activation='relu', return_sequences=True, input_shape=(SEQ_LENGTH, data.shape[1])),
    tf.keras.layers.LSTM(32, activation='relu', return_sequences=False),
    tf.keras.layers.RepeatVector(SEQ_LENGTH),
    tf.keras.layers.LSTM(32, activation='relu', return_sequences=True),
    tf.keras.layers.LSTM(64, activation='relu', return_sequences=True),
    tf.keras.layers.TimeDistributed(tf.keras.layers.Dense(data.shape[1]))
])

model.compile(optimizer='adam', loss='mse')
model.summary()

history = model.fit(X_train, X_train, batch_size=32, epochs=20, validation_split=0.1, shuffle=True)


# -------------------------------
# 4Ô∏è‚É£ Compute Reconstruction Errors
# -------------------------------

X_pred = model.predict(X_sequences)
mse = np.mean(np.power(X_sequences - X_pred, 2), axis=(1, 2))

threshold = np.percentile(mse[normal_idx], 95)
print("Error threshold:", threshold)

y_pred = (mse > threshold).astype(int)


# -------------------------------
# 5Ô∏è‚É£ Performance Metrics
# -------------------------------

precision = precision_score(y_sequences, y_pred)
recall = recall_score(y_sequences, y_pred)
f1 = f1_score(y_sequences, y_pred)

print("\nüìå PERFORMANCE METRICS")
print(f"Precision: {precision:.4f}")
print(f"Recall:    {recall:.4f}")
print(f"F1 Score:  {f1:.4f}")


# -------------------------------
# 6Ô∏è‚É£ Visualization
# -------------------------------

plt.figure(figsize=(14, 4))
plt.plot(mse, label="Reconstruction Error")
plt.axhline(y=threshold, color='r', linestyle='--', label="Threshold")
plt.title("Reconstruction Error Over Time")
plt.legend()
plt.show()

plt.figure(figsize=(14, 4))
plt.plot(y_sequences, label="True Labels")
plt.plot(y_pred, alpha=0.7, label="Predicted Anomalies")
plt.legend()
plt.title("True vs Predicted Anomalies")
plt.show()